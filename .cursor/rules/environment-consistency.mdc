---
description: Rules for keeping all 4 cluster environments in sync
globs: environments/**/*.tf, environments/**/*.tfvars
alwaysApply: false
---

# Environment Consistency

There are 4 cluster environments that MUST stay structurally identical. When modifying one, apply the same change to all 4.

## The 4 Cluster Environments

| Environment | Cluster Type | Cloud | RHCS Auth |
|---|---|---|---|
| `commercial-classic` | Classic | AWS Commercial | `client_id` + `client_secret` |
| `commercial-hcp` | HCP | AWS Commercial | `client_id` + `client_secret` |
| `govcloud-classic` | Classic | AWS GovCloud | `token` + `token_url` |
| `govcloud-hcp` | HCP | AWS GovCloud | `token` + `token_url` |

Note: `account-hcp` exists but is a separate account-level environment, not a cluster environment.

## Two-Phase Deployment and Tfvars Structure

Each environment uses **stacked tfvars** for a two-phase deployment:

```
environments/<environment>/
├── cluster-dev.tfvars       # Phase 1: cluster infrastructure (install_gitops = false)
├── gitops-dev.tfvars        # Phase 2: GitOps overlay (install_gitops = true)
├── cluster-prod.tfvars      # Phase 1: cluster infrastructure (install_gitops = false)
├── gitops-prod.tfvars       # Phase 2: GitOps overlay (install_gitops = true)
└── <name>-dev.tfvars        # Personal/named cluster tfvars
    <name>-dev-gitops.tfvars # Personal/named gitops overlay
```

Usage:
- Phase 1: `terraform apply -var-file=cluster-dev.tfvars`
- Phase 2: `terraform apply -var-file=cluster-dev.tfvars -var-file=gitops-dev.tfvars`
- Destroy: `terraform destroy -var-file=cluster-dev.tfvars` (gitops overlay not needed)

The gitops overlay ONLY contains:
- `install_gitops = true`
- `enable_layer_*` flags
- Layer-specific config (certmanager, monitoring, OADP settings)
- Commented `gitops_cluster_token` for subsequent runs

The cluster tfvars MUST NOT duplicate gitops settings. The cluster tfvars MUST set `install_gitops = false`.

## What MUST Be Identical (Terraform Files)

- `versions.tf`: Same provider requirements (kubernetes, kubectl, aws, rhcs, etc.)
- `variables.tf`: Same variable definitions (type, description, default)
- `outputs.tf`: Same output definitions
- Module calls: Same variables passed to `module "gitops"`, `module "gitops_resources"`, etc.
- Provider blocks: `kubernetes {}` and `kubectl {}` use the same `effective_k8s_host`/`effective_k8s_token` pattern
- `effective_k8s_host` local: `var.install_gitops ? local.effective_api_url : "https://localhost"`
- `effective_k8s_token` local: `var.gitops_cluster_token != null ? var.gitops_cluster_token : try(module.cluster_auth[0].token, "")`
- `kubernetes` provider MUST include `config_path = "/dev/null"` to suppress `~/.kube/config` loading

## What MUST Be Identical (Tfvars Structure)

- All 4 environments MUST have the same set of `cluster-*.tfvars` and `gitops-*.tfvars` files
- `cluster-dev.tfvars` across environments: Same variable keys, different values
- `gitops-dev.tfvars` across environments: Same layer enable flags and config structure
- Comments and section headers should be consistent across environments

## Critical: Classic vs HCP Architecture Differences

ROSA Classic and HCP have fundamental infrastructure differences that MUST be respected when editing environments. Getting these wrong causes silent failures (timeouts, unreachable endpoints).

### API Port

| Cluster Type | API URL Pattern | Port |
|---|---|---|
| Classic | `https://api.<domain>:6443` | **6443** |
| HCP | `https://api.<domain>` | **443** (default HTTPS) |

The `effective_api_url` local MUST use the correct port:
- Classic: `"https://api.${module.rosa_cluster.domain}:6443"`
- HCP: `"https://api.${module.rosa_cluster.domain}"` (no port suffix)

**NEVER** hardcode `:6443` for HCP environments. HCP hosted control planes expose the API on port 443.

### OAuth URL Pattern

The `cluster-auth` module auto-discovers the OAuth URL via `.well-known/oauth-authorization-server`. If discovery fails, the fallback patterns differ:

| Cluster Type | OAuth URL Pattern |
|---|---|
| Classic | `https://oauth-openshift.apps.<domain>` |
| HCP | `https://oauth.<domain>` (hosted control plane) |

The `get-token.sh` script probes both patterns automatically. Do NOT assume one pattern works for both.

### Cluster Module Data Sources

Both cluster modules (`rosa-classic` and `rosa-hcp`) use a post-creation data source to re-read cluster attributes after the `cluster_ready` wait. This ensures `api_url` and `console_url` are populated in state:
- Classic: `data "rhcs_cluster_rosa_classic" "info"`
- HCP: `data "rhcs_cluster_rosa_hcp" "info"`

## Allowed Differences

- `locals { cluster_type }`: "classic" or "hcp"
- `locals { effective_api_url }`: Classic uses `:6443`, HCP uses default HTTPS port (see above)
- `provider "rhcs"`: Commercial uses `client_id`/`client_secret`; GovCloud uses `token`/`token_url`/`client_id`
- `provider "aws" { default_tags }`: Different `Project` and optional `Compliance` tag
- `rhcs` version pin: May differ between classic (>= 1.6.7) and hcp (>= 1.6.3)
- KMS locals: GovCloud uses `var.cluster_kms_key_arn`; Commercial may use module output
- tfvars values: Environment-specific settings (cluster name, region, etc.)
- GovCloud gitops tfvars: Include VPN connectivity note in header
- GovCloud cluster tfvars: FIPS, private_cluster, etcd_encryption are hardcoded/mandatory

## Workflow

When adding a variable, output, or module parameter:

1. Make the change in one environment
2. Immediately replicate to the other 3
3. Verify with `grep` that the change appears identically in all 4 files
4. If the variable is GitOps-specific, update the gitops tfvars templates
5. If the variable is cluster-specific, update the cluster tfvars templates
